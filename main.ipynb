{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Face Recognition (LBPH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Step 1 - Importing required libraries and creating function to detect the face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:17: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:17: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<ipython-input-1-92730622dfbb>:17: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if faces is ():\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "# Load HAAR face classifier\n",
    "face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Load functions\n",
    "def face_extractor(img):\n",
    "    # Function detects faces and returns the cropped face\n",
    "    # If no face detected, it will return no image\n",
    "    \n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "    \n",
    "    if faces is ():\n",
    "        return None\n",
    "    \n",
    "    # Crop all faces found\n",
    "    for (x,y,w,h) in faces:\n",
    "        cropped_face = img[y:y+h, x:x+w]\n",
    "\n",
    "    return cropped_face\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2.a: Creating training data for my face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Collecting Samples Complete for my face\n"
     ]
    }
   ],
   "source": [
    "# Initializing Webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "count1 = 0\n",
    "\n",
    "# Collect 200 samples of your face from webcam input\n",
    "while True:\n",
    "\n",
    "    ret, frame1 = cap.read()\n",
    "    if face_extractor(frame1) is not None:\n",
    "        count1 += 1\n",
    "        face1 = cv2.resize(face_extractor(frame1), (250, 250))\n",
    "        face1 = cv2.cvtColor(face1, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Save file in specified directory with unique name\n",
    "        file_name_path1 = './faces/user1/' + str(count1) + '.jpg'\n",
    "        cv2.imwrite(file_name_path1, face1)\n",
    "\n",
    "        # Put count on images and display live count\n",
    "        cv2.putText(face1, str(count1), (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "        cv2.imshow('Face Cropper', face1)\n",
    "        \n",
    "    else:\n",
    "        print(\"Face not found\")\n",
    "        pass\n",
    "\n",
    "    if cv2.waitKey(1) == 13 or count1 == 200: #13 is the Enter Key\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()      \n",
    "print(\"Collecting Samples Complete for my face\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2.b: Creating training data for my younger brother's face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "count2 = 0\n",
    "\n",
    "# Collect 200 samples of your face from webcam input\n",
    "while True:\n",
    "\n",
    "    ret, frame2 = cap.read()\n",
    "    if face_extractor(frame2) is not None:\n",
    "        count2 += 1\n",
    "        face2 = cv2.resize(face_extractor(frame2), (250, 250))\n",
    "        face2 = cv2.cvtColor(face2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Save file in specified directory with unique name\n",
    "        file_name_path2 = './faces/user2/' + str(count2) + '.jpg'\n",
    "        cv2.imwrite(file_name_path2, face2)\n",
    "\n",
    "        # Put count on images and display live count\n",
    "        cv2.putText(face2, str(count2), (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "        cv2.imshow('Face Cropper', face2)\n",
    "        \n",
    "    else:\n",
    "        print(\"Face not found\")\n",
    "        pass\n",
    "\n",
    "    if cv2.waitKey(1) == 13 or count2 == 200: #13 is the Enter Key\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()      \n",
    "print(\"Collecting Samples Complete for my younger brother\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3.a: Train Model for my face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained sucessefully for my face\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Get the training data we previously made\n",
    "data_path1 = './faces/user1/'\n",
    "onlyfiles1 = [f for f in listdir(data_path1) if isfile(join(data_path1, f))]\n",
    "\n",
    "# Create arrays for training data and labels\n",
    "Training_Data1, Labels1 = [], []\n",
    "\n",
    "# Open training images in our datapath\n",
    "# Create a numpy array for training data\n",
    "for i, files in enumerate(onlyfiles1):\n",
    "    image_path1 = data_path1 + onlyfiles1[i]\n",
    "    images1 = cv2.imread(image_path1, cv2.IMREAD_GRAYSCALE)\n",
    "    Training_Data1.append(np.asarray(images1, dtype=np.uint8))\n",
    "    Labels1.append(i)\n",
    "\n",
    "# Create a numpy array for both training data and labels\n",
    "Labels1 = np.asarray(Labels1, dtype=np.int32)\n",
    "\n",
    "# Initialize facial recognizer\n",
    "# model = cv2.face.createLBPHFaceRecognizer()\n",
    "# NOTE: For OpenCV 3.0 use cv2.face.createLBPHFaceRecognizer()\n",
    "# pip install opencv-contrib-python\n",
    "# model = cv2.createLBPHFaceRecognizer()\n",
    "\n",
    "my_model  = cv2.face_LBPHFaceRecognizer.create()\n",
    "# Let's train our model \n",
    "my_model.train(np.asarray(Training_Data1), np.asarray(Labels1))\n",
    "print(\"Model trained sucessefully for my face\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3.b: Train Model for my younger brother's face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained sucessefully for my younger brother\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Get the training data we previously made\n",
    "data_path2 = './faces/user2/'\n",
    "onlyfiles2 = [f for f in listdir(data_path2) if isfile(join(data_path2, f))]\n",
    "\n",
    "# Create arrays for training data and labels\n",
    "Training_Data2, Labels2 = [], []\n",
    "\n",
    "# Open training images in our datapath\n",
    "# Create a numpy array for training data\n",
    "for i, files in enumerate(onlyfiles2):\n",
    "    image_path2 = data_path2 + onlyfiles2[i]\n",
    "    images2 = cv2.imread(image_path2, cv2.IMREAD_GRAYSCALE)\n",
    "    Training_Data2.append(np.asarray(images2, dtype=np.uint8))\n",
    "    Labels2.append(i)\n",
    "\n",
    "# Create a numpy array for both training data and labels\n",
    "Labels2 = np.asarray(Labels2, dtype=np.int32)\n",
    "\n",
    "# Initialize facial recognizer\n",
    "# model = cv2.face.createLBPHFaceRecognizer()\n",
    "# NOTE: For OpenCV 3.0 use cv2.face.createLBPHFaceRecognizer()\n",
    "# pip install opencv-contrib-python\n",
    "# model = cv2.createLBPHFaceRecognizer()\n",
    "\n",
    "gf_model  = cv2.face_LBPHFaceRecognizer.create()\n",
    "# Let's train our model \n",
    "gf_model.train(np.asarray(Training_Data2), np.asarray(Labels2))\n",
    "print(\"Model trained sucessefully for my younger brother\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4 - Run Our Facial Recognition and creating function for detecting face "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:14: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:14: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<ipython-input-5-7aacf58159a5>:14: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if faces is ():\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import smtplib\n",
    "\n",
    "\n",
    "face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "def face_detector(img, size=0.5):\n",
    "    \n",
    "    # Convert image to grayscale\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "    if faces is ():\n",
    "        return img, []\n",
    "    \n",
    "    \n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,255),2)\n",
    "        roi = img[y:y+h, x:x+w]\n",
    "        roi = cv2.resize(roi, (250, 250))\n",
    "    return img, roi\n",
    "\n",
    "\n",
    "# Open Webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    image, face = face_detector(frame)\n",
    "    \n",
    "    try:\n",
    "        face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Pass face to prediction model\n",
    "        # \"results\" comprises of a tuple containing the label and the confidence value\n",
    "        results = my_model.predict(face)\n",
    "        gf_res = gf_model.predict(face)\n",
    "        # harry_model.predict(face_)\n",
    "        \n",
    "        #if results[1] < 500:\n",
    "        confidence = int( 100 * (1 - (results[1])/400) )\n",
    "            #display_string = str(confidence) + '% Confident it is User1'\n",
    "            \n",
    "        #elif gf_res[1] < 500:\n",
    "        confidence_gf = int( 100 * (1 - (gf_res[1])/400) )\n",
    "            #display_string = str(confidence_gf) + '% Confident it is User2'\n",
    "            \n",
    "            \n",
    "       # cv2.putText(image, display_string, (100, 120), cv2.FONT_HERSHEY_COMPLEX, 1, (255,120,150), 2)\n",
    "        \n",
    "        if confidence > 85:\n",
    "            cv2.putText(image, \"Hey Kapil\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "            cv2.imshow('Face Recognition', image )\n",
    "            #Sending email\n",
    "            try:\n",
    "                s = smtplib.SMTP('smtp.gmail.com', 587)\n",
    "                s.starttls()\n",
    "                s.login(\"kapil181kumar@gmail.com\", \"electro@statics\")\n",
    "                message = \"My face detected \"\n",
    "                s.sendmail(\"kapil181kumar@gmail.com\", \"kapil437kumar@gmail.com\", message)\n",
    "                s.quit()\n",
    "            except:\n",
    "                print(\"Can't send theemail\")\n",
    "                \n",
    "            # WhatsApp message\n",
    "            try:\n",
    "                import datetime\n",
    "                import pywhatkit\n",
    "                now = datetime.datetime.now()\n",
    "                hour = int( now.strftime(\"%H\") )\n",
    "                min = int( now.strftime(\"%M\") ) + 2\n",
    "                pywhatkit.sendwhatmsg(\"+918278816437\", \n",
    "                                      \"Hello from GeeksforGeeks\", \n",
    "                                      hour, \n",
    "                                      min)\n",
    "            except:\n",
    "                print(\"Can't send the message\")\n",
    "                \n",
    "            \n",
    "        elif confidence_gf > 85:\n",
    "            cv2.putText(image, \"Hey brother\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "            cv2.imshow('Face Recognition', image )\n",
    "            \n",
    "            try:\n",
    "                import boto3\n",
    "                import time\n",
    "\n",
    "                ec2_res = boto3.client(\"ec2\")\n",
    "\n",
    "                #Creating ec2 instance\n",
    "                x = ec2_res.run_instances(ImageId = \"ami-0ad704c126371a549\", \n",
    "                                          InstanceType = \"t2.micro\",\n",
    "                                          MaxCount = 1,\n",
    "                                          MinCount = 1,\n",
    "                                          TagSpecifications = [\n",
    "                                                  {\n",
    "                                                    'ResourceType': 'volume', \n",
    "                                                    'Tags': [\n",
    "                                                                  {\n",
    "                                                                   'Key': 'Name',\n",
    "                                                                   'Value': 'Task_6_EC2'\n",
    "                                                                   },\n",
    "                                                            ]\n",
    "                                                   },\n",
    "                                                               ],\n",
    "                                              )\n",
    "\n",
    "                # creating ebs vulime of 5GB\n",
    "                y = ec2_res.create_volume(AvailabilityZone = (x.get(\"Instances\")[0]).get(\"Placement\").get(\"AvailabilityZone\"),\n",
    "                                                              Size = 5,\n",
    "                                                              VolumeType = 'gp2',\n",
    "                                                              TagSpecifications = [\n",
    "                                                                                     {\n",
    "                                                                                         'ResourceType': 'volume', \n",
    "                                                                                         'Tags': [\n",
    "                                                                                                    {\n",
    "                                                                                                        'Key': 'Name',\n",
    "                                                                                                        'Value': 'Task_6_EBS'\n",
    "                                                                                                     },\n",
    "                                                                                                 ]\n",
    "                                                                                      },\n",
    "                                                                                   ],\n",
    "                                        )\n",
    "\n",
    "                # Time given in order to give suitable time for instance to get started\n",
    "                time.sleep(60)\n",
    "\n",
    "                # Attachung Volume\n",
    "                ec2_res.attach_volume(\n",
    "                Device = '/dev/xvdb',\n",
    "                InstanceId = x.get(\"Instances\")[0].get(\"InstanceId\"),\n",
    "                VolumeId = y.get('VolumeId'),\n",
    "                      )\n",
    "                \n",
    "            except:\n",
    "                print(\"Can't create instance and ebs volume\")\n",
    "            \n",
    "        else:\n",
    "            cv2.putText(image, \"I dont know, how r u\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "            cv2.imshow('Face Recognition', image )\n",
    "\n",
    "    except:\n",
    "        cv2.putText(image, \"No Face Found\", (220, 120) , cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "        cv2.putText(image, \"looking for face\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "        cv2.imshow('Face Recognition', image )\n",
    "        pass\n",
    "        \n",
    "    if cv2.waitKey(1) == 13: #13 is the Enter Key\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
